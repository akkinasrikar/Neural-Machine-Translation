{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Translator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L0RHpVc4YxM"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaD6bFAC4YxS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoVWWVGn4YxT"
      },
      "source": [
        "import re\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import numpy as np\n",
        "import unicodedata"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C4kf7mV4YxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b0bd51e-c319-48b6-c48a-55ae1c2b6693"
      },
      "source": [
        "path_to_zip=tf.keras.utils.get_file('spa-eng.zip', \n",
        "                                 origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n",
        "                                   extract=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
            "2646016/2638744 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muRZJtqy4YxV"
      },
      "source": [
        "path_to_file=os.path.dirname(path_to_zip)+\"/spa-eng/spa.txt\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YoH4pzuf4YxW",
        "outputId": "f0375258-4923-4f02-ba9c-aa75513492da"
      },
      "source": [
        "path_to_file"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/root/.keras/datasets/spa-eng/spa.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSiydqnK4YxY"
      },
      "source": [
        "#convert unicode file to ascii\n",
        "#u\"Klüft skräms inför på fédéral électoral große\" ---> unicode version\n",
        "#u\"Kluft skrams infor pa federal electoral groe\" ----> ascii version\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDZBCbRT4YxZ"
      },
      "source": [
        "def preprocess_sentence(w):\n",
        "    w=unicode_to_ascii(w.lower().strip())\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
        "    w = w.strip()\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JI4yoah4Yxa"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "nl_sentence = u\"¿Puedo tomar prestado este libro?\""
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0py8t9_4Yxb",
        "outputId": "990e7997-3926-40ed-e464-be39737892d6"
      },
      "source": [
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(nl_sentence))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "<start> ¿ puedo tomar prestado este libro ? <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dzleaNrd4Yxc",
        "outputId": "97afffe2-fc7c-4f67-b258-aaa9e8f0677e"
      },
      "source": [
        "unk_sentence=\"Klüft skräms inför på fédéral électoral große\"\n",
        "preprocess_sentence(unk_sentence)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> kluft skrams infor pa federal electoral gro e <end>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mmva17i34Yxd"
      },
      "source": [
        "def create_dataset(path,num_examples):\n",
        "    lines=io.open(path,encoding='UTF-8').read().strip().split('\\n')\n",
        "    word_pairs=[[preprocess_sentence(w) for w in line.split('\\t')[0:2]] for line in lines[:num_examples]]\n",
        "    \n",
        "    return zip(*word_pairs)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nr7gqi9K4Yxd",
        "outputId": "969bf153-e450-4ba6-d780-735c6acef9bf"
      },
      "source": [
        "en,nl=create_dataset(path_to_file,None)\n",
        "l=len(en)\n",
        "print(l)\n",
        "for i in range(5):\n",
        "    n=np.random.randint(l)\n",
        "    print(en[n])\n",
        "    print(nl[n])\n",
        "    print(\"-----------------------------\")\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "118964\n",
            "<start> the island is warm all year . <end>\n",
            "<start> la isla es calida todo el ano . <end>\n",
            "-----------------------------\n",
            "<start> don t be late to school again . <end>\n",
            "<start> no vuelvas a llegar tarde al colegio . <end>\n",
            "-----------------------------\n",
            "<start> he didn t say in which year he was born . <end>\n",
            "<start> el no dijo en que ano nacio . <end>\n",
            "-----------------------------\n",
            "<start> tom was shot by a policeman . <end>\n",
            "<start> a tom le disparo un policia . <end>\n",
            "-----------------------------\n",
            "<start> i want more of that . <end>\n",
            "<start> quiero mas de eso . <end>\n",
            "-----------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEYmWrlt4Yxe"
      },
      "source": [
        "def tokenize(language):\n",
        "    language_tokenizer=tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    language_tokenizer.fit_on_texts(language)\n",
        "    tensor=language_tokenizer.texts_to_sequences(language)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "    return tensor,language_tokenizer"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9i7dC18_4Yxf",
        "outputId": "2ca61824-96f1-40d7-ffee-20beaecb1ad0"
      },
      "source": [
        "tokenize(en[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 1],\n",
              "        [ 4],\n",
              "        [ 2],\n",
              "        [ 5],\n",
              "        [ 6],\n",
              "        [ 2],\n",
              "        [ 3],\n",
              "        [ 0],\n",
              "        [ 7],\n",
              "        [ 8],\n",
              "        [ 0],\n",
              "        [ 9],\n",
              "        [ 0],\n",
              "        [ 1],\n",
              "        [10],\n",
              "        [11],\n",
              "        [12],\n",
              "        [ 3]], dtype=int32),\n",
              " <keras_preprocessing.text.Tokenizer at 0x7fc25e97e590>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukBvrZji4Yxf"
      },
      "source": [
        "def load_dataset(path,num_examples=None):\n",
        "    targ_lang,inp_lang=create_dataset(path,num_examples)\n",
        "    input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "    target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "    return input_tensor,target_tensor,inp_lang_tokenizer,targ_lang_tokenizer"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctDxOFgH4Yxg"
      },
      "source": [
        "num_examples = 100000\n",
        "input_tensor,target_tensor,inp_lang,targ_lang=load_dataset(path_to_file, num_examples)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPkQh9Ij4Yxg",
        "outputId": "8e4c5699-20e6-416c-c615-e54ec9fa1413"
      },
      "source": [
        "max_length_targ,max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "print(max_length_targ,max_length_inp)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "17 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20LHdk7a4Yxh",
        "outputId": "60c57eca-5733-47b3-9243-510338f6d5ea"
      },
      "source": [
        "input_tensor_train,input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80000 80000 20000 20000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYAm7skQ4Yxh"
      },
      "source": [
        "def convert(lang, tensor):\n",
        "    for t in tensor:\n",
        "        if t!=0:\n",
        "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BseFP2_64Yxh",
        "outputId": "9235ba8c-3ca7-4766-c215-8af60c7e2970"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print (\" \")\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "37 ----> estoy\n",
            "1985 ----> deseando\n",
            "4 ----> que\n",
            "557 ----> llegue\n",
            "12 ----> la\n",
            "616 ----> navidad\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            " \n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "4 ----> i\n",
            "90 ----> am\n",
            "257 ----> looking\n",
            "987 ----> forward\n",
            "7 ----> to\n",
            "576 ----> christmas\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yf7OQfo34Yxi"
      },
      "source": [
        "buffer_size=len(input_tensor_train)\n",
        "batch_size=64\n",
        "steps_per_epoch = len(input_tensor_train)//batch_size\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(buffer_size)\n",
        "dataset = dataset.batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hznmxpz4Yxi",
        "outputId": "6cade487-b6d1-4183-cc1a-9d0dd85327c9"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 20]), TensorShape([64, 17]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3GPutqS4Yxj"
      },
      "source": [
        "Bahdanau attention for the encoder\n",
        "\n",
        "FC = Fully connected (dense) layer\n",
        "\n",
        "EO = Encoder output\n",
        "\n",
        "H = hidden state\n",
        "\n",
        "X = input to the decoder\n",
        "\n",
        "pseudo-code:\n",
        "\n",
        "score = FC(tanh(FC(EO) + FC(H)))\n",
        "\n",
        "attention weights = softmax(score, axis = 1). Softmax by default is applied on the last axis but here we want to apply it on the 1st axis, since the shape of score is (batch_size, max_length, hidden_size). Max_length is the length of our input. Since we are trying to assign a weight to each input, softmax should be applied on that axis.\n",
        "\n",
        "context vector = sum(attention weights * EO, axis = 1). Same reason as above for choosing axis as 1.\n",
        "\n",
        "embedding output = The input to the decoder X is passed through an embedding layer.\n",
        "\n",
        "merged vector = concat(embedding output, context vector)\n",
        "\n",
        "This merged vector is then given to the GRU\n",
        "\n",
        "References:\n",
        "\n",
        "https://www.tensorflow.org/tutorials/text/nmt_with_attention\n",
        "\n",
        "https://arxiv.org/pdf/1409.0473.pdf\n",
        "\n",
        "https://github.com/tensorflow/nmt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymX2At4a4Yxj"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,vocab_size,embedding_dim,enc_units,batch_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "        \n",
        "    def call(self,x,hidden):\n",
        "        x=self.embedding(x)\n",
        "        output,state=self.gru(x,initial_state=hidden)\n",
        "        return output,state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_size, self.enc_units))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEWxuFDc4Yxk"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units,batch_size)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veK_L2sT4Yxk"
      },
      "source": [
        "sample_hidden=encoder.initialize_hidden_state()"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6aWOagL4Yxk"
      },
      "source": [
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1BrGzJB4Yxl",
        "outputId": "6739a462-eeb6-4a3b-fc2a-2c9e1cbee0a2"
      },
      "source": [
        "print (f'Encoder output shape: (batch size, sequence length, units) {sample_output.shape}')\n",
        "print (f'Encoder Hidden state shape: (batch size, units) {sample_hidden.shape}')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 20, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yryi3wuV4Yxm"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, query, values):\n",
        "\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "        score = self.V(tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values)))\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpSg1wIG4Yxm",
        "outputId": "70adc8f0-819e-47ea-f699-9f345ac243af"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 20, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF1tlSCF4Yxn"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "        x = self.embedding(x)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output, state = self.gru(x)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state, attention_weights"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bavcIMHr4Yxn",
        "outputId": "49393bb3-74c2-4fc7-cd6e-484e1be2acdc"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, batch_size)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((batch_size, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 10785)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsX2YrkB4Yxo"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kUw1BVE4Yxo"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnTa6mwH4Yxp"
      },
      "source": [
        "@tf.function\r\n",
        "def train_step(inp, targ, enc_hidden):\r\n",
        "  loss = 0\r\n",
        "\r\n",
        "  with tf.GradientTape() as tape:\r\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\r\n",
        "    dec_hidden = enc_hidden\r\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * batch_size, 1)\r\n",
        "    \r\n",
        "    for t in range(1, targ.shape[1]):\r\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\r\n",
        "      loss += loss_function(targ[:, t], predictions)\r\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\r\n",
        "\r\n",
        "  batch_loss = (loss / int(targ.shape[1]))\r\n",
        "\r\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\r\n",
        "\r\n",
        "  gradients = tape.gradient(loss, variables)\r\n",
        "\r\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\r\n",
        "\r\n",
        "  return batch_loss"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vHjdNFq5Lzb",
        "outputId": "e4fb6816-0ddf-495b-eb32-9df123df91bb"
      },
      "source": [
        "epochs = 10\r\n",
        "\r\n",
        "for epoch in range(epochs):\r\n",
        "  start = time.time()\r\n",
        "  enc_hidden = encoder.initialize_hidden_state()\r\n",
        "  total_loss = 0\r\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\r\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\r\n",
        "    total_loss += batch_loss\r\n",
        "    if batch % 100 == 0:\r\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\r\n",
        "                                                   batch,\r\n",
        "                                                   batch_loss.numpy()))\r\n",
        "  if (epoch + 1) % 2 == 0:\r\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\r\n",
        "\r\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\r\n",
        "                                      total_loss / steps_per_epoch))\r\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.5489\n",
            "Epoch 1 Batch 100 Loss 2.1116\n",
            "Epoch 1 Batch 200 Loss 2.0521\n",
            "Epoch 1 Batch 300 Loss 1.8592\n",
            "Epoch 1 Batch 400 Loss 1.7546\n",
            "Epoch 1 Batch 500 Loss 1.7540\n",
            "Epoch 1 Batch 600 Loss 1.5703\n",
            "Epoch 1 Batch 700 Loss 1.4615\n",
            "Epoch 1 Batch 800 Loss 1.4870\n",
            "Epoch 1 Batch 900 Loss 1.5539\n",
            "Epoch 1 Batch 1000 Loss 1.2781\n",
            "Epoch 1 Batch 1100 Loss 1.1866\n",
            "Epoch 1 Batch 1200 Loss 1.1692\n",
            "Epoch 1 Loss 1.6527\n",
            "Time taken for 1 epoch 223.05416417121887 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.1712\n",
            "Epoch 2 Batch 100 Loss 1.1311\n",
            "Epoch 2 Batch 200 Loss 1.0302\n",
            "Epoch 2 Batch 300 Loss 0.7353\n",
            "Epoch 2 Batch 400 Loss 0.7840\n",
            "Epoch 2 Batch 500 Loss 0.9653\n",
            "Epoch 2 Batch 600 Loss 0.8258\n",
            "Epoch 2 Batch 700 Loss 0.7271\n",
            "Epoch 2 Batch 800 Loss 0.6632\n",
            "Epoch 2 Batch 900 Loss 0.6744\n",
            "Epoch 2 Batch 1000 Loss 0.6868\n",
            "Epoch 2 Batch 1100 Loss 0.6506\n",
            "Epoch 2 Batch 1200 Loss 0.7265\n",
            "Epoch 2 Loss 0.8196\n",
            "Time taken for 1 epoch 208.6992471218109 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.5288\n",
            "Epoch 3 Batch 100 Loss 0.4748\n",
            "Epoch 3 Batch 200 Loss 0.5209\n",
            "Epoch 3 Batch 300 Loss 0.4958\n",
            "Epoch 3 Batch 400 Loss 0.4838\n",
            "Epoch 3 Batch 500 Loss 0.5834\n",
            "Epoch 3 Batch 600 Loss 0.6057\n",
            "Epoch 3 Batch 700 Loss 0.5693\n",
            "Epoch 3 Batch 800 Loss 0.4650\n",
            "Epoch 3 Batch 900 Loss 0.5452\n",
            "Epoch 3 Batch 1000 Loss 0.4774\n",
            "Epoch 3 Batch 1100 Loss 0.4972\n",
            "Epoch 3 Batch 1200 Loss 0.4692\n",
            "Epoch 3 Loss 0.4864\n",
            "Time taken for 1 epoch 207.57822799682617 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.3830\n",
            "Epoch 4 Batch 100 Loss 0.3304\n",
            "Epoch 4 Batch 200 Loss 0.3658\n",
            "Epoch 4 Batch 300 Loss 0.3340\n",
            "Epoch 4 Batch 400 Loss 0.3734\n",
            "Epoch 4 Batch 500 Loss 0.2907\n",
            "Epoch 4 Batch 600 Loss 0.3531\n",
            "Epoch 4 Batch 700 Loss 0.3212\n",
            "Epoch 4 Batch 800 Loss 0.3075\n",
            "Epoch 4 Batch 900 Loss 0.3686\n",
            "Epoch 4 Batch 1000 Loss 0.3018\n",
            "Epoch 4 Batch 1100 Loss 0.3634\n",
            "Epoch 4 Batch 1200 Loss 0.3628\n",
            "Epoch 4 Loss 0.3267\n",
            "Time taken for 1 epoch 208.30505990982056 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.1970\n",
            "Epoch 5 Batch 100 Loss 0.2131\n",
            "Epoch 5 Batch 200 Loss 0.2099\n",
            "Epoch 5 Batch 300 Loss 0.2225\n",
            "Epoch 5 Batch 400 Loss 0.2102\n",
            "Epoch 5 Batch 500 Loss 0.1974\n",
            "Epoch 5 Batch 600 Loss 0.2012\n",
            "Epoch 5 Batch 700 Loss 0.2895\n",
            "Epoch 5 Batch 800 Loss 0.2885\n",
            "Epoch 5 Batch 900 Loss 0.2772\n",
            "Epoch 5 Batch 1000 Loss 0.2435\n",
            "Epoch 5 Batch 1100 Loss 0.2344\n",
            "Epoch 5 Batch 1200 Loss 0.2453\n",
            "Epoch 5 Loss 0.2349\n",
            "Time taken for 1 epoch 207.8027470111847 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.1732\n",
            "Epoch 6 Batch 100 Loss 0.1984\n",
            "Epoch 6 Batch 200 Loss 0.1758\n",
            "Epoch 6 Batch 300 Loss 0.1834\n",
            "Epoch 6 Batch 400 Loss 0.1799\n",
            "Epoch 6 Batch 500 Loss 0.1433\n",
            "Epoch 6 Batch 600 Loss 0.2096\n",
            "Epoch 6 Batch 700 Loss 0.1555\n",
            "Epoch 6 Batch 800 Loss 0.1717\n",
            "Epoch 6 Batch 900 Loss 0.2180\n",
            "Epoch 6 Batch 1000 Loss 0.1729\n",
            "Epoch 6 Batch 1100 Loss 0.2007\n",
            "Epoch 6 Batch 1200 Loss 0.1990\n",
            "Epoch 6 Loss 0.1780\n",
            "Time taken for 1 epoch 208.56477570533752 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.1267\n",
            "Epoch 7 Batch 100 Loss 0.1235\n",
            "Epoch 7 Batch 200 Loss 0.0876\n",
            "Epoch 7 Batch 300 Loss 0.1077\n",
            "Epoch 7 Batch 400 Loss 0.1235\n",
            "Epoch 7 Batch 500 Loss 0.1298\n",
            "Epoch 7 Batch 600 Loss 0.1461\n",
            "Epoch 7 Batch 700 Loss 0.1041\n",
            "Epoch 7 Batch 800 Loss 0.1335\n",
            "Epoch 7 Batch 900 Loss 0.1573\n",
            "Epoch 7 Batch 1000 Loss 0.1833\n",
            "Epoch 7 Batch 1100 Loss 0.2079\n",
            "Epoch 7 Batch 1200 Loss 0.1583\n",
            "Epoch 7 Loss 0.1383\n",
            "Time taken for 1 epoch 207.11463689804077 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0861\n",
            "Epoch 8 Batch 100 Loss 0.1182\n",
            "Epoch 8 Batch 200 Loss 0.0748\n",
            "Epoch 8 Batch 300 Loss 0.0932\n",
            "Epoch 8 Batch 400 Loss 0.1058\n",
            "Epoch 8 Batch 500 Loss 0.1000\n",
            "Epoch 8 Batch 600 Loss 0.1359\n",
            "Epoch 8 Batch 700 Loss 0.1109\n",
            "Epoch 8 Batch 800 Loss 0.1034\n",
            "Epoch 8 Batch 900 Loss 0.1389\n",
            "Epoch 8 Batch 1000 Loss 0.1273\n",
            "Epoch 8 Batch 1100 Loss 0.1568\n",
            "Epoch 8 Batch 1200 Loss 0.1227\n",
            "Epoch 8 Loss 0.1114\n",
            "Time taken for 1 epoch 209.0249559879303 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0862\n",
            "Epoch 9 Batch 100 Loss 0.1020\n",
            "Epoch 9 Batch 200 Loss 0.1024\n",
            "Epoch 9 Batch 300 Loss 0.0526\n",
            "Epoch 9 Batch 400 Loss 0.0652\n",
            "Epoch 9 Batch 500 Loss 0.0917\n",
            "Epoch 9 Batch 600 Loss 0.0923\n",
            "Epoch 9 Batch 700 Loss 0.1276\n",
            "Epoch 9 Batch 800 Loss 0.0975\n",
            "Epoch 9 Batch 900 Loss 0.0925\n",
            "Epoch 9 Batch 1000 Loss 0.1324\n",
            "Epoch 9 Batch 1100 Loss 0.0933\n",
            "Epoch 9 Batch 1200 Loss 0.1227\n",
            "Epoch 9 Loss 0.0907\n",
            "Time taken for 1 epoch 207.9201843738556 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0411\n",
            "Epoch 10 Batch 100 Loss 0.0538\n",
            "Epoch 10 Batch 200 Loss 0.0562\n",
            "Epoch 10 Batch 300 Loss 0.0705\n",
            "Epoch 10 Batch 400 Loss 0.0916\n",
            "Epoch 10 Batch 500 Loss 0.0776\n",
            "Epoch 10 Batch 600 Loss 0.0861\n",
            "Epoch 10 Batch 700 Loss 0.0839\n",
            "Epoch 10 Batch 800 Loss 0.0803\n",
            "Epoch 10 Batch 900 Loss 0.0519\n",
            "Epoch 10 Batch 1000 Loss 0.0823\n",
            "Epoch 10 Batch 1100 Loss 0.0699\n",
            "Epoch 10 Batch 1200 Loss 0.0860\n",
            "Epoch 10 Loss 0.0796\n",
            "Time taken for 1 epoch 208.32564663887024 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSWSPR5P5d-y"
      },
      "source": [
        "def evaluate(sentence):\r\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\r\n",
        "\r\n",
        "  sentence = preprocess_sentence(sentence)\r\n",
        "\r\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\r\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\r\n",
        "                                                         maxlen=max_length_inp,\r\n",
        "                                                         padding='post')\r\n",
        "  inputs = tf.convert_to_tensor(inputs)\r\n",
        "\r\n",
        "  result = ''\r\n",
        "\r\n",
        "  hidden = [tf.zeros((1, units))]\r\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\r\n",
        "\r\n",
        "  dec_hidden = enc_hidden\r\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\r\n",
        "\r\n",
        "  for t in range(max_length_targ):\r\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\r\n",
        "                                                         dec_hidden,\r\n",
        "                                                         enc_out)\r\n",
        "\r\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\r\n",
        "    attention_plot[t] = attention_weights.numpy()\r\n",
        "\r\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\r\n",
        "\r\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\r\n",
        "\r\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\r\n",
        "      return result, sentence, attention_plot\r\n",
        "\r\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\r\n",
        "\r\n",
        "  return result, sentence, attention_plot"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BUjhy3G93iS"
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\r\n",
        "  fig = plt.figure(figsize=(10,10))\r\n",
        "  ax = fig.add_subplot(1, 1, 1)\r\n",
        "  ax.matshow(attention, cmap='viridis')\r\n",
        "\r\n",
        "  fontdict = {'fontsize': 14}\r\n",
        "\r\n",
        "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\r\n",
        "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\r\n",
        "\r\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "\r\n",
        "  plt.show()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxsznZV76RgF"
      },
      "source": [
        "def translate(sentence):\r\n",
        "  result, sentence, attention_plot = evaluate(sentence)\r\n",
        "\r\n",
        "  print('Input: %s' % (sentence))\r\n",
        "  print('Predicted translation: {}'.format(result))\r\n",
        "\r\n",
        "  attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\r\n",
        "  plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jd90eUs46X0v",
        "outputId": "a3f18e28-aa4b-483b-b2f0-86a380b9c723"
      },
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fc25bf88b90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "Gc25EBUW6cQx",
        "outputId": "72b2c1b4-ccb3-4ad1-ab22-f39f90cc14fa"
      },
      "source": [
        "translate(u'hace mucho frio aqui.')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> hace mucho frio aqui . <end>\n",
            "Predicted translation: it s very cold here . <end> \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAJwCAYAAAC08grWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZilB1nn/d+ddBYSCMgiQRRBkVUQSYtsI3FAMwPur6IICjIvcYERBEdFXCIzgEBQUVwIKkxYVGDgRcQBkcWggDGgQmSNYYssIRqBkD19v388p6G66M6CnbpPd30+11XXdeo5p07dddKp861nre4OAMCEQ6YHAAC2LyECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRImugqr6mql5fVXeangUAtpIQWQ8PTXJ8kocPzwEAW6pc9G5WVVWSDyZ5bZJvT/Jl3X3F6FAAsEWsEZl3fJLrJfnJJJcnuf/oNACwhYTIvIcmeWl3X5jkj1efA8C2YNPMoKo6OsnHkjygu99UVXdJ8pYkN+vuf5+dDgCufdaIzPp/kpzX3W9Kku7+hyTvT/IDo1MBcMCrqqOr6oer6vrTs1wZITLrh5K8YNOyFyR52NaPAsBB5oFJnpvlvWZt2TQzpKq+IskHkty+u9+/YfmXZzmK5g7d/b6h8VgDVXXnJD+d5A5JOsm7kjy9u88cHQw4IFTVG5LcNMmF3b1zep59ESKwhqrqO5K8LMmbkvz1avG9Vx/f092vnJoNWH9Vdcsk70tytyRvTXLX7n7X5Ez7IkQGVdUtknyk9/Ifoapu0d0fHhiLNVBV70jy8u7+5U3Ln5jkO7v762YmAw4EVfWLSY7v7vtW1cuSvL+7f3Z6rr2xj8isDyS5yeaFVXWj1X1sX7dJ8vy9LH9+kttu8SzAgeeH8/nfIS9M8uDVCTTXjhCZVVm2/W923SQXb/EsrJdzkxy3l+XHJfnEFs8CHECq6p5JbpbkpatFr0xyVJL7jQ11JXZMD7AdVdVvrm52kqdU1YUb7j40yza9f9jywVgnz0ny7Kq6dZI3r5bdK8vOq08fmwo4EDw0ySu6+4Ik6e5Lq+rFWY7IfO3kYHtjH5EBqz2Zk+Q+WU5gdumGuy/NctTMyRuPpmF7Wa1CfUySxyX5stXij2aJkN/c235FAFV1RJKPJ3lQd796w/J7J3lNkpvuDpR1IUSGrN5oXpzk4d39mel5WF9Vdb0k8e8EuCpVdeMs1yx7QXfv2nTfQ5L8ZXd/fGS4fRAiQ6rq0Cz7gXzduh5SBQDXNvuIDOnuK6rqQ0kOn56F9VNVN0zypCT3TfKl2bRjeXcfMzEXwP4mRGb9zyS/WlUP6e7zpodhrfxBkq9PckqWfUOsugT2qao+kKv5e6K7v+paHucasWlmUFW9M8mtkhyW5Jwkn914f3ffeWIu5lXVp5N8S3f/7fQswPqrqsdt+PS6SR6b5PQsB0QkyT2yHJH5jO5+4haPd6WsEZn10qt+CNvUuUnWas92YH119zN2366q5yV5anc/eeNjqurxSe64xaNdJWtEYA1V1fdnuXLmQ9ftUDtgva3WqN61u8/atPzWSd6+bvuYWSPC2qiqn0jyyCybq762u8+uqp9LcnZ3v3h2umvfalPdxr8MbpXk3NVOzZdtfKzNdsCV+GyS45OctWn58Uku3PzgaUJkUFUdnuQJSR6U5BZZ9hX5nO4+dGKuCVX1mCQ/k+SpSX51w13/kuRRWc65crCzqQ7YH349yW9X1c4sV95NkrtnOePqSVND7YtNM4Oq6qlJvj/JU7L8w/mFJLdM8gNJfrG7nz033daqqvckeVx3v6qqPpPl/CpnV9Udk5zW3TcaHhFGVdVdk/xDd+9a3d6n7n77Fo3FmqqqByZ5dJLbrxa9O8kz13HtshAZtDrc6se7+9WrN9+7dPc/V9WPJ7lvd3/v8IhbpqouSnK77v7QphC5TZZfvkcNj7ilquo+SdLdf7WX5d3dp40Mxpiq2pXk2O4+d3W7s1w4c7PeTmtTOfDZNDPrpkl2n1X1giQ3WN1+dZZNFNvJ2UnumuRDm5bfP59/jbaTX0+yt0PsjsmyanVvV+bl4HarJJ/ccBuuUlXdIF94QsR/Gxpnr4TIrA9nuaDZh7PsVHRCkrdlOd77osG5Jpyc5FlVdVSWv/LuUVU/lGW/kYePTjbjtkn+cS/Lz1zdxzbT3R/a223YrKq+MsnvZdk5dePZuyvLmrS1WmMmRGa9PMspvN+a5JlJ/qiqHpHk5tlml3rv7udW1Y4kT05yVJLnZzmj6E9295+MDjfjoiQ3S/KBTctvnj2v1sw2ZB8RrsJzs6xh/285AM7MbB+RNVJV35jkXkne191/Nj3PlNXVIw/p7nOnZ5lSVS/MciTVd3T3+atlN0zyiiTndPeDJudj1j72EfncL3P7iGxvVXVBkrt395nTs1wdQmRQVX1Tkjd39+Wblu9Ics/ttEPi6uiYQ7v7HZuW3znJ5dvtCsVVdbMkp2W54N3u1+TOWc64ep/u/ujUbMxbrXrf6LAs1yZ6QpLHd/f/3fqpWBercxI9rLvfNj3L1SFEBlXVFUlutvkv/6q6UZJzt9NfNVX1N0l+u7tftGn5DyR5VHffe2ayOav9ZR6c5C6rRX+f5EXdvXYnJNoKVfWfk9why1/+7+ruNwyPtHaq6luT/HJ332t6Fuas/l/5uSQ/sfnsqutIiAxarV69aXd/ctPy2yQ5Y91Ow3ttWh2y+/V7OSXxV2c5JfH1ZyZjWlXdPMv+VMdl2d6dLDt5n5Hku60d+ryq+posh7sfPT0Lc1a/T4/IslPqJUn2WOu+bu8tdlYdUFV/urrZSV5QVZdsuPvQJF+b5M1bPtisK5LsLTa+JHs/V8JBraq+58ru7+6XbdUsa+A3s/z7uHV3fyBJquqrkrxgdd+2Od/Obqv9hfZYlGXn5pOSvHfLB2LdPGp6gGvCGpEBVfXc1c2HZjl1+cZDdS9N8sEkz+nu87Z4tDFV9Yosbzbf191XrJbtSPKSJId197dNzrfVVmvL9qaT7bUz4uoCXsdvPhJkdfrq123HtWUbdlbdY3GSjyT5/u5+6xd+Fawna0QGdPePJElVfTDJyd392dmJ1sLPJPnrJGdV1V+vlt07yXWTfNPYVEO6e48TEK2i7OuzHNb9hJGhZu3tL6bt/FfUN2/6fFeWk52dtXnnd7anqrppkh9K8tVZLhlyXlXdK8lHd69ZXBfWiAyqqkOSpLt3rT4/Nsm3ZdkRb7ttmtl9pMijsufOmb9jH4DPq6p7Jvnd7v666Vm2SlW9PMlNkjyouz+yWnaLJC9M8snuvtLNWLDdVNVxSV6X5TxEd8xy+Yyzq+qkJLfp7h+cnG8zITKoqv5vkld39zOr6rpJ3pPk6CxrAf5bd586OiBrp6rukOT07r7u9Cxbpaq+IsmfZtl3auPOqu/Mcp6Vc6Zmm7I69P9q2U6nAWBRVW/IcrHQX9507a57JPnj7t58+Pcom2Zm7cyySSJJvifJp7NcQ+LBSX46ybYLkar6siwn8tp4WuJt98t0L2fO3L0z4s9mWVO0bXT3R1avx/2S3G61+N3d/ZeDY017Yz6/aWr3ztybP9+9bNvsT8TnHJflrKqbfSzLNc7WihCZdd0k/766/a1JXt7dl1XV65P89txYW28VIC/Ksj/I7jNGblxdt91+mZ6RvV9d9a3Zhtfe6WXV7WtXHyybcE9O8qQkb1ktu0eSn8/yx42dVbe3i7IccbjZ7bKcFHGtCJFZH05yr6p6ZZYL3n3favkNk2y3k1b9RpajZu6Q5O+S/Jcs5f7EJD81ONeUzVdX3ZVlf4iLJ4bZalX12Cz7B128ur1P3f1rWzTWOvmfSR7d3RvD7OyqOjfJ07r764fmYj28IskvV9Xu95Suqltmuar7/5kaal/sIzKoqn40ybOSXJDkQ0nu2t27quonk3xXd//n0QG3UFV9IskDuvuM1eGaO7v7fVX1gCx7fN99eMQtt9rr/V5ZTvO++TLevzMy1Bapqg9k+Tfwr6vb+9Ld/VVbNde6qKqLsvy+ePem5XdI8rbuvs7MZKyDqjomyZ9nuSzE0Uk+nuUPuzcn+a/rdqSmEBm22rv5Fkle290XrJY9IMm/d/ffjA63hVbxcefu/uDqsOaHdPdfV9WtkvxTdx81O+HWqqqHJPn9LJtmzs+em6m6u79sZDDWQlWdkeSsJD/S3Retll0ny1VXb93dOyfnYz2sTvV+1yx/yLx9XfersmlmSFVdP8sb75uSbL4w0b8n2VYXectyxNDtspzM7R+S/FhVfSTJI5P8y+BcU56U5GlJnridzwtRVYdlOb/MD3e3M4Z+3o8n+bMk/1JVuy+KeKcsmzcfMDYV4za+t3T365O8fsN998pyeojzxwbcC2tEhlTV9bLswXzCxjUfVfV1SU5PcvNtdmbVB2c5g+rzVkdIvDrJjbNcJ+Gh3f3i0QG3WFWdn+S47j57epZpq/0e7t3d75ueZZ1U1dFJfjDJ7VeL3p3loohrtdqdrXUgvrcIkUFV9cIkF3T3j25YdnKWE858x9xk81ZXnr1dkg+v2/80W6GqnpXkvd39W9OzTKuqpydJd/+P6VnWyepsu3fL3g9333aH/vN5B9p7ixAZVFUnJPmjJMd296WrM62ek+Wy99vpomZJkqr6/iT3zd53zly7/3muTVV1eJL/L8u1h96Z5LKN93f3EyfmmlBVv5Pl3DofyLIZc4+/+Lv7JyfmmlRVt0vyyixHV1WWTTI7svw7uWTdrq7K1jrQ3lvsIzLrtVmO9/62JC/L8iZ8eJZfMNvK6q/exyR5Q5azZ273Qv7RLIcwn5fk1tm0s2qWw5oPWqszh755tX/M7ZPsvuDd5iNktuu/k9/IEmV3yXJExF2yXL36d5P8wuBcrIcD6r3FGpFhVfXUJLft7u+qqlOTfKa7Hzk911ZbHb77yO5+6fQs62C1X8RTuvvXp2eZUFVXJLlZd59bVWcn+Ybu/tfpudZFVf1rkvt095lV9akkd+vu91bVfZL8VnffeXhEhh1I7y3WiMw7NcnbVhfx+u4s5bodHZLlaBkWh2a5vsp2dX6WzQ7nJrllNm2qI5XPn/Twk0lunuS9WVa/33pqKNbKAfPeYo3IGlidE+CiJDfu7ttf1eMPRlX1pCSXdfdJ07Osg9WOZZ/eTvuCbFRVz07y0Cx7/98iyxvsFXt77DY9odlpSX69u19eVS9KcqMkT07yiCyHblojwgHz3mKNyHo4Ncs23ydMD7KVquo3N3x6SJIHV9W3JHlHvnDnzO22Q+JRSf7f1U5n2/H1+LEsa4S+JsmvZTlR12dGJ1ovT8pyxsxk2SfkVVn2rzovyQOnhlo3VfXuJF/T3dv1ve6AeG/Zrv9x1s0Lslyg6LnTg2yxO236fPemmdttWr4dV9vdPp+/yu62ez1WF7l7VfK58x88o7uFyEp3v2bD7bOT3L6qbpjk/Laae6PfzrK2aLs6IN5bbJoBAMbYAQwAGCNEAIAxQmRNVNWJ0zOsE6/Hnrwee/J67MnrsSevx57W/fUQIutjrf+hDPB67MnrsSevx568HnvyeuxprV8PIQIAjNn2R80cXkf0kXX0VT/wWnZZX5LD6ojpMVI71uOI7kt3XZTDD7nO9BjJurwel1+Yw3ccNT1Gdh22Hn+7XHbpZ3PY4fP/3x5y8eXTIyRJLr3iwhx+6Py/j6zJ+8na/P7YtWt6giTJpX1xDq8jp8fIp68477zuvsnm5evxW3bQkXV07r7jhOkx1sahN97Oh9x/oV3Hej02uvjY+Tf/dXLUez4xPcJ6uXyvJ7/dtvqzF171g7aR1/zbcz60t+Xr8ecNALAtCREAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGCBEAYIwQAQDGHBQhUlXPq6o/m54DALhmdkwPsJ88OkklSVW9McmZ3f2o0YkAgKt0UIRId39qegYA4Jo7KEKkqp6X5MZJzktynyT3qapHru6+VXd/cGg0AOBKHBQhssGjk9wmyXuS/Pxq2SfnxgEArsxBFSLd/amqujTJhd398X09rqpOTHJikhyZo7ZqPABgk4PiqJlrqrtP6e6d3b3zsDpiehwA2La2ZYgAAOvhYAyRS5McOj0EAHDVDsYQ+WCSu1XVLavqxlV1MP6MAHBQOBjfpE/OslbkXVmOmLnF7DgAwL4cFEfNdPfDNtx+X5J7zE0DAFxdB+MaEQDgACFEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxQgQAGCNEAIAxO6YHGHedI5M73m56irVx9rcdMz3CWrnp6ZdNj7BWznmI12OjWz/jetMjrJdd0wOsl/rUp6dHOCBYIwIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMAYIQIAjBEiAMCYgy5EquqbquqtVXVBVX2qqk6vqq+dngsA+EI7pgfYn6pqR5JXJPmDJA9OcliSuya5YnIuAGDvDqoQSXJMkhskeWV3//Nq2Xs2P6iqTkxyYpIcefj1t246AGAPB9Wmme7+tyTPS/KaqnpVVT22qm6xl8ed0t07u3vnYTuO2vI5AYDFQRUiSdLdP5LkG5OcluQ7kry3qk6YnQoA2JuDLkSSpLv/sbuf2t3HJ3ljkofOTgQA7M1BFSJVdauq+tWqumdVfWVVfXOSOyd51/RsAMAXOth2Vr0wyW2SvCTJjZN8IskLkzx1cigAYO8OqhDp7k8k+Z7pOQCAq+eg2jQDABxYhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMGbH9ADT6tLLcsgHPjo9xtq45csunx5hrZz9/V8yPcJa+em7/Pn0CGvlFVfcZ3qEtXLIpy+cHmGtXHHppdMjHBCsEQEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxhzwIVJVh0/PAAB8cbY0RKrqxKr6RFUdumn5i6rqT1e3v72q3lZVF1fVB6rqSRtjo6o+WFUnVdUfVtW/J3lhVb2+qp616TmPqaoLq+p7tuSHAwCusa1eI/KSJNdP8i27F1TVdZN8Z5IXVNUJSV6Y5FlJ7pjk4Um+N8mTNz3PY5O8J8nOJD+f5DlJfrCqjtjwmAcluSDJK6+VnwQA+A/b0hDp7vOT/HmSB29Y/F1JLk/yp0mekOTp3f3c7v7n7n5Dkp9N8mNVVRu+5q+6+2ndfVZ3vz/Jy5LsSvLdGx7z8CSndvdlm+dYrZk5o6rOuHTXxfv1ZwQArr6JfURekOS7quqo1ecPTvJ/uvviJMcleUJVXbD7I8mLkhyd5NgNz3HGxifs7kuSPD9LfKSq7pjkbkn+YG8DdPcp3b2zu3cefsiR+/FHAwCuiR0D3/NVWdaAfGdVvS7J/ZKcsLrvkCS/kmUTzmaf3HD7s3u5//eTvKOqbpElSN7S3e/eb1MDAPvdlodId19SVS/Jsibkxkk+nuSNq7vfnuR23X3WF/G8/1RVf5vkEUkekmUzDwCwxibWiCTL5pnXJblVkj/q7l2r5U9M8mdV9aEkL86y5uRrk9ytu3/majzvc5L8XpLLkvzJfp8aANivps4j8qYk/5LkDlmiJEnS3a9J8oAk35zk9NXHzyX58NV83j9JcmmSF3f3Z/bnwADA/jeyRqS7O8kt93HfXyT5iyv52r1+3coNklwn+9hJFQBYL1ObZvarqjosyY2ynG/k77v7b4ZHAgCuhgP+FO8r90rysST3zLKzKgBwADgo1oh09xuT1FU9DgBYLwfLGhEA4AAkRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABgjRACAMUIEABizY3qAcbs6fdHF01OsjV1nvn96hLXy5Te5y/QIa+XHfuRfpkdYK8+74zHTI6yV651zxPQIa2XHx8+dHuGAYI0IADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADBGiAAAY4QIADDmgAyRqjqpqs68isc8q6reuEUjAQBfhAMyRACAg4MQAQDGjIVILR5XVe+vqkuq6pyqesrqvjtV1V9W1UVV9W9V9byquv6VPNehVXVyVZ2/+viNJIdu2Q8DAHxRJteIPDnJLyZ5SpI7Jvm+JB+pqqOTvCbJBUnuluS7k9wzyR9eyXM9LskjkvxokntkiZAHX2uTAwD7xY6Jb1pV103yU0ke0927A+OsJG+pqkckOTrJD3X3Z1aPPzHJG6rq1t191l6e8jFJntbdL149/tFJTriS739ikhOT5Mg6ej/9VADANTW1RuQOSY5I8rq93Hf7JO/YHSErb06ya/V1e1htsrlZkrfsXtbdu5L87b6+eXef0t07u3vn4XXkF/cTAAD/YQfazqo9PQAAsP9Mhci7k1yS5L77uO9OVXW9DcvumWXWd29+cHd/KsnHktx997Kqqiz7lwAAa2xkH5Hu/kxVPTPJU6rqkiSnJblRkuOS/O8kv5Lk1Kr6pSRfkuTZSV62j/1DkuSZSR5fVe9L8s4kP5Flc83Hrt2fBAD4jxgJkZXHJzk/y5EzX57kE0lO7e4Lq+qEJL+R5PQkFyd5RZJHX8lzPSPJsUl+f/X585O8MMv+JgDAmhoLkdUOpb+6+th83zuz9802u+8/KclJGz6/PMtROD+1v+cEAK49B9rOqgDAQUSIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjdkwPMK137cquCy+cHoM1ddhfnzk9wlr5lgc+bHqEtXLoL5w7PcJaucUNvB4bfewhN50eYb28f++LrREBAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMYIEQBgjBABAMZsaYhU1Rur6llb+T0BgPVljQgAMOaAD5GqOmx6BgDgizMRIodU1ZOr6ryqOreqTq6qQ5Kkqg6vqqdW1TlVdWFV/V1VnbD7C6vq+Krqqrp/VZ1eVZcmOaEWP1NV/1xVF1XVO6vqIQM/GwBwDewY+J4PTvLMJPdMcpckL0rytiR/lOS5Sb46yQ8mOSfJ/ZO8sqq+obv/ccNzPDXJ45KcleQzSf5Xku9N8sgk701yjyTPqarzu/tVmweoqhOTnJgkR+aoa+FHBACujokQeVd3/9Lq9vuq6hFJ7ltVpyd5UJJbdveHV/c/q6rul+RHk/zEhuc4qbv/Ikmq6ugkj03yrd39ptX9H6iqu2UJky8Ike4+JckpSXJM3bD3748HAFxdEyHyjk2ffzTJlya5a5JK8q6q2nj/EUlev+lrzthw+w5Jjkzy6qraGBWHJfngfpgXALiWTITIZZs+7yz7qhyyuv0Ne3nMRZs+/+yG27v3c/n2JB/e9LjNzwMArJGJENmXv8+yRuTY7n7DNfi6dyW5JMlXdvfmNScAwBpbmxDp7vdV1QuTPK+qHpfk7UlumOT4JGd398v28XWfqaqTk5xcyzad05JcN8ndk+xa7Q8CAKyhtQmRlR9J8oQkT0vy5Un+LcnpSa5qDckvJvlEkp9O8rtJPp3kH1bPAwCsqS0Nke4+fi/LHrbh9mVJTlp97O3r35hl883m5Z3kt1YfAMAB4oA/syoAcOASIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAGCECAIwRIgDAmB3TA8A668sunx5hrRz6d++eHmGtXP+/33x6hLVy2iPuND3CWjny6Z+aHmG9fNfeF1sjAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCM2TE9wISqOjHJiUlyZI4angYAtq9tuUaku0/p7p3dvfOwHDE9DgBsW9syRACA9SBEAIAxQgQAGHPQhkhVPaqq3jM9BwCwbwdtiCS5cZLbTg8BAAPS0E8AAAcASURBVOzbQRsi3X1Sd9f0HADAvh20IQIArD8hAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCM2TE9AKy1XVdMT7BW+tJd0yOsl/M/NT3BWrnOJ46dHmGtnPp9z50eYa0ct4/l1ogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGOECAAwRogAAGMOmBCpqp+uqg9OzwEA7D8HTIgAAAef/RIiVXVMVd1gfzzXNfieN6mqI7fyewIA+9cXHSJVdWhVnVBVL0ry8SRft1p+/ao6parOrarPVNVfVdXODV/3sKq6oKruW1VnVtVnq+oNVXWrTc//M1X18dVjT01y3U0j3D/Jx1ff615f7M8BAMy5xiFSVXesqqcl+UiSP0ny2ST/JclpVVVJXpXk5km+LcnXJzktyeur6mYbnuaIJI9P8vAk90hygyS/t+F7PDDJ/0ryy0numuS9SR67aZQXJvnBJNdL8tqqOquqfmlz0OzjZzixqs6oqjMuyyXX9CUAAPaTqxUiVXWjqvrJqnpbkr9Pcrskj05ybHc/ortP6+5O8s1J7pLke7v79O4+q7t/McnZSX5ow1PuSPLI1WPekeTkJMevQiZJHpPkf3f3s7v7fd39pCSnb5ypuy/v7j/v7gclOTbJk1ff//1V9caqenhVbV6LsvtrT+nund2987AccXVeAgDgWnB114j89yTPTHJxktt093d090u6++JNjzsuyVFJPrnapHJBVV2Q5GuTfPWGx13S3e/d8PlHkxye5EtWn98+yVs2Pffmzz+nuz/d3X/Y3d+c5BuS3DTJHyT53qv58wEAA3ZczcedkuSyJD+c5MyqenmS5yd5XXdfseFxhyT5RJL/tJfn+PSG25dvuq83fP01VlVHZNkU9JAs+478U5a1Kq/4Yp4PANgaV+uNv7s/2t1P6u7bJrlfkguS/HGSc6rqGVV1l9VD355lbcSu1WaZjR/nXoO53p3k7puW7fF5Le5dVc/OsrPsbyU5K8lx3X3X7n5md59/Db4nALDFrvEaiO5+a3f/eJKbZdlkc5skf1dV/ynJXyb5mySvqKr/WlW3qqp7VNWvrO6/up6Z5KFV9Yiq+pqqenySb9z0mIck+YskxyR5UJKv6O7/0d1nXtOfCQCYcXU3zXyB7r4kyUuTvLSqvjTJFd3dVXX/LEe8PCfJl2bZVPM3SU69Bs/9J1X1VUmelGWfkz9N8mtJHrbhYa/LsrPsp7/wGQCAA0EtB7tsX8fUDfsb677TY8CB4XMHtpEkh97ohtMjrJVzHnrb6RHWyqmP+vXpEdbKcbf8yNu6e+fm5U7xDgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwBghAgCMESIAwJjq7ukZRh1TN+xvrPtOjwEAB7W/7Je+rbt3bl5ujQgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMEaIAABjhAgAMGbH9AATqurEJCcmyZE5angaANi+tuUake4+pbt3dvfOw3LE9DgAsG1tyxABANaDEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxggRAGCMEAEAxlR3T88wqqo+meRD03MkuXGS86aHWCNejz15Pfbk9diT12NPXo89rcvr8ZXdfZPNC7d9iKyLqjqju3dOz7EuvB578nrsyeuxJ6/Hnrwee1r318OmGQBgjBABAMYIkfVxyvQAa8brsSevx568HnvyeuzJ67GntX497CMCAIyxRgQAGCNEAIAxQgQAGCNEAIAxQgQAGPP/A8XebQaH8wg9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OW9fCf26ebh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}